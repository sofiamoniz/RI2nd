"""
IR, November 2020
Assignment 2: Ranked Retrieval
Autors: Alina Yanchuk, 89093
        Ana Sofia Fernandes, 88739
"""

from indexing.CorpusReader import CorpusReader
from indexing.Results import Results
from indexing.InvertedIndexer import InvertedIndexer
from indexing.WeightedIndexer import WeightedIndexer
import time
import os
import psutil
import sys

## Class that acts as a pipeline for the all indexing process ( calls all the other classes and methods  )
class DocumentIndexer:

    def __init__(self,tokenizer_type,input_file,weighted_indexer_type):
        self.tokenizer_type=tokenizer_type
        self.input_file=input_file
        self.weighted_indexer_type=weighted_indexer_type


    def document_indexer(self):

        """
        Index the documents and prints the results and relevant information
        
        Follows this pipeline:

                Read Corpus     
                    |
                Tokenize
                    |             -----> Here, we already have all documents tokenized.
                Index  ( Inverted Index -> Weighted Index )    ( one document at a time )  
                    |             -----> Here, we already have all documents indexed 
                Store and print results
    
        """
    
        doc_ids={}
        total_docs=0
        total_terms=0
        indexing_time=0
        if self.weighted_indexer_type=="-lnc.ltc": self.weighted_indexer_type="-lnc_ltc"
        

        start_time = time.time()
        corpusReader = CorpusReader(self.input_file,self.tokenizer_type) ## Corpus Reader with Tokenization
        corpus,real_doc_ids=corpusReader.read_content() # corpus: [[doc1_terms_after_tokenization],[doc2_terms_after_tokenization]...]
                                                        # real_doc_ids: [real_doc1_id,real_doc2_id,...]
        total_docs=len(corpus)
        for j in range(total_docs):    
            total_terms=total_terms+len(corpus[j])  # vocabulary size or number of terms
 

        indexer = InvertedIndexer(total_docs) # Inverted Indexer
        for i in range(total_docs):   # Index one document at a time. The id's are auto generated by incrementation, starting at id=1 
            generated_id=i+1 
            indexer.index_document(corpus[i],generated_id)
            doc_ids[generated_id]=real_doc_ids[i]
        indexer.sort_inverted_index() # All documents have been indexed and the final Inverted Indexer created!
        inverted_index=indexer.get_inverted_index()


        weighted_indexer = WeightedIndexer(total_docs, inverted_index ,indexer.get_doc_len(), total_terms)  ## Weighted Indexer
        if(self.weighted_indexer_type=="-bm25"):    # BM25
            weighted_indexer.weighted_index_bm25()
        else:
            weighted_indexer.weighted_index_lnc_ltc()  # LNC.LTC
        weighted_index=weighted_indexer.get_weighted_index()
        indexing_time=time.time()-start_time

        results = Results(inverted_index,doc_ids,self.tokenizer_type,self.input_file,weighted_index,self.weighted_indexer_type[1:]) ## Results ( writes informations to files )
        #results.write_inverted_index_to_file()
        results.write_weighted_index_to_file()
        results.write_document_ids_to_file()



        # Print results:
        if(self.tokenizer_type=="-s"):
            print("\n    Tokenizer used: Simple     Ranking Method: "+self.weighted_indexer_type[1:]+"\n"
                    +"\n--- Indexation time:  %s seconds." % (round(indexing_time,3))
                    + "\n--- File with the Weighted Index: results/simpleTokenizer/weightedIndex_"+self.weighted_indexer_type[1:]+".txt")

        else:
            print("\n    Tokenizer used: Simple     Ranking Method: "+self.weighted_indexer_type[1:]+"\n"
                    +"\n--- Indexation time:  %s seconds." % (round(indexing_time,3))
                    + "\n--- File with the Weighted Index: results/improvedTokenizer/weightedIndex_"+self.weighted_indexer_type[1:]+".txt")
